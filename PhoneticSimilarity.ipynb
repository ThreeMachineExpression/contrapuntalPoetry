{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PhoneticSimilarity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOx/6NDxqab/vfHyFPinosV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThreeMachineExpression/contrapuntalPoetry/blob/main/PhoneticSimilarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPCyH2eLsbbF"
      },
      "source": [
        "\r\n",
        "Parts of this notebook are based on Max Woolf's aitextgen notebook, as updated by Allison Parrish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxzLNBUjsxSv"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYABCBZZs2ie",
        "outputId": "82bb66b2-17ee-476f-af11-de2df8eaaa63"
      },
      "source": [
        "# Freeze versions of dependencies for now\r\n",
        "!pip install tensorflow==1.15.0 keras==2.2.5 \"h5py<3.0.0\"\r\n",
        "!pip3 install pytorch-lightning==0.7.6\r\n",
        "!pip3 install transformers==2.9.1\r\n",
        "!pip3 install fire==0.3.0\r\n",
        "\r\n",
        "!pip install -q aitextgen==0.2.3\r\n",
        "\r\n",
        "from aitextgen import aitextgen\r\n",
        "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive\r\n",
        "\r\n",
        "mount_gdrive()\r\n",
        "\r\n",
        "!pip install annoy\r\n",
        "!pip install pronouncing\r\n",
        "!pip install pincelate\r\n",
        "import pronouncing\r\n",
        "import pincelate\r\n",
        "pin = pincelate.Pincelate()\r\n",
        "\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "import random\r\n",
        "import textwrap\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import logging\r\n",
        "logging.basicConfig(\r\n",
        "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\r\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\r\n",
        "        level=logging.INFO\r\n",
        "    )\r\n",
        "\r\n",
        "kPhoneticSimilarityVectorsRepo = \"https://github.com/aparrish/phonetic-similarity-vectors\"\r\n",
        "\r\n",
        "!git clone {kPhoneticSimilarityVectorsRepo}\r\n",
        "\r\n",
        "!python -m spacy download en_core_web_md\r\n",
        "\r\n",
        "%cd phonetic-similarity-vectors\r\n",
        "from featurephone import phone_feature_map as pfm\r\n",
        "%cd ..\r\n",
        "\r\n",
        "pfm['STOP'] = ()\r\n",
        "\r\n",
        "vowels = ['AO','AA','IY','UW','EH','IH','UH','AH','AE','EY','AY','OW','AW','OY',\r\n",
        "          'ER','STOP']\r\n",
        "\r\n",
        "# When deciding how close two syllables are, these constants indicate how much\r\n",
        "# weight to give vowel features, stress, and consonant features\r\n",
        "kDistanceWeightVowels = 4.0\r\n",
        "kDistanceWeightStress = 5.0\r\n",
        "kDistanceWeightConsonants = 1.0\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning==0.7.6 in /usr/local/lib/python3.6/dist-packages (0.7.6)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.7.0+cu101)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.15.0)\n",
            "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (3.13)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (0.18.2)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch-lightning==0.7.6) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch-lightning==0.7.6) (3.7.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (51.3.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (3.3.3)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.4.0)\n",
            "Requirement already satisfied: transformers==2.9.1 in /usr/local/lib/python3.6/dist-packages (2.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.1.95)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: fire==0.3.0 in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire==0.3.0) (1.15.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: annoy in /usr/local/lib/python3.6/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pronouncing in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cmudict>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pronouncing) (0.4.5)\n",
            "Requirement already satisfied: pincelate in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: pronouncing>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from pincelate) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from pincelate) (0.22.2.post1)\n",
            "Requirement already satisfied: Keras>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pincelate) (2.2.5)\n",
            "Requirement already satisfied: cmudict>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pronouncing>=0.2.0->pincelate) (0.4.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->pincelate) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->pincelate) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->pincelate) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.0->pincelate) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.0->pincelate) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.0->pincelate) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.0->pincelate) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.0->pincelate) (2.10.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'phonetic-similarity-vectors'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Total 32 (delta 0), reused 0 (delta 0), pack-reused 32\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n",
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051304 sha256=0729af81a74cba9ba95a67b8242f02d4390e8788dba7d598eb9016fa765fc537\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3lcml_vy/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "/content/phonetic-similarity-vectors\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZkOeQ8V4zhX"
      },
      "source": [
        "from_folder = \"aitextgenDreamFineTuning\"\r\n",
        "\r\n",
        "for file in [\"pytorch_model.bin\", \"config.json\"]:\r\n",
        "  if from_folder:\r\n",
        "    copy_file_from_gdrive(file, from_folder)\r\n",
        "  else:\r\n",
        "    copy_file_from_gdrive(file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9afxhkk46WG",
        "outputId": "c14ca060-a695-4aa1-c6f5-8af9652cf7d4"
      },
      "source": [
        "ai = aitextgen(model=\"pytorch_model.bin\", config=\"config.json\", to_gpu=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:aitextgen:Loading GPT-2 model from provided pytorch_model.bin.\n",
            "INFO:aitextgen:Using the default GPT-2 Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXb_7Rin5hr-"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DdUOTYE5tad",
        "outputId": "c51240f2-2c5c-4855-b99d-969dcd35a44b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan 22 09:41:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    39W / 300W |   1931MiB / 16130MiB |     12%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H4_V452Dy5u",
        "outputId": "766a75a3-91a9-4606-f245-440e7c955aee"
      },
      "source": [
        "ai.generate()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "You've wanted to create a story for a while only to have it leak out and into the void, where nothing real happens.\n",
            "And then it's on the news instead of the people you know.\n",
            "You try to turn it off for a while, but everyone keeps saying stupid things and it doesn't really work.\n",
            "And then it all just goes back to pretending that everything's okay and everything's okay.\n",
            "Like when the bright ball of light descends and lands in your throat and you can sing and everyone knows they're loved, the elderly women who are finally marrying feel in their bones that everything's okay and they really do love me.\n",
            "I don't need anyone to love me anymore, I need someone to love me, and I NEEDED to hear that everyone was loved so much before.\n",
            "I went to medical school so that I can provide proper care to the people I've hit over the head with 18th-century furniture.\n",
            "Everything I need to know about this job interview is in the open field outside the hospital.\n",
            "When I apply for this gig, there are rules against being late, nudity, and being a serial rapist.\n",
            "I have to get used to it.\n",
            "I don't know how to train for this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftsVytZcEGLj"
      },
      "source": [
        "# Phonetic Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnfSUgmEqNd"
      },
      "source": [
        "# Strategy:\r\n",
        "# Split text into syllable buckets\r\n",
        "# In each bucket, include the vowel sound, stress, and all of the bordering phonemes\r\n",
        "#  (so a consonant between syllables goes in both buckets)\r\n",
        "# Measure the distance between two buckets as \r\n",
        "#   a * (manhattan distance of consonant features)\r\n",
        "# + b * (manhattan distance of vowel features)\r\n",
        "# + c * (stress distance)\r\n",
        "# (with a, b, c tuned as desired to emphasize different similarities)\r\n",
        "#\r\n",
        "# Pauses get a bucket of their own.\r\n",
        "\r\n",
        "def phones_for_word_fb(word):\r\n",
        "  \"\"\"Phones for word - either 1st entry in the CMU pronouncing dictionary\r\n",
        "   or fallback to Pincelate sound-out if it's not in the dictionary.\r\n",
        "\r\n",
        "   Returns a list of phones.\r\n",
        "\r\n",
        "   word - lowercase word, no spaces or punctuation\r\n",
        "  \"\"\"\r\n",
        "  try:\r\n",
        "    return pronouncing.phones_for_word(word)[0].split()\r\n",
        "  except IndexError:\r\n",
        "    return pin.soundout(word)\r\n",
        "\r\n",
        "def arpabetPlusFromText(string):\r\n",
        "  \"\"\"Turns text into a list of arpabet phones, + STOP for punctuation.\r\n",
        "  One stop for ,; two stops for .:?! or double dash.\r\n",
        "  Turns a hyphen between letters (as in \"use-case\") into a space,\r\n",
        "   but in \"a phrase - like this one\" replaces it with a STOP\r\n",
        "\r\n",
        "  Discards all other punctuation and non-alpha characters (including numbers).\r\n",
        "\r\n",
        "  string -- text to convert to phones\"\"\"\r\n",
        "\r\n",
        "  lidx = ridx = 0\r\n",
        "  \r\n",
        "  phones = []\r\n",
        "  doublestops = \".:?!\"\r\n",
        "  singlestops = \",;\"\r\n",
        "\r\n",
        "  while (lidx < len(string)):\r\n",
        "    if string[lidx].isalpha():\r\n",
        "      while ((ridx < len(string)) and (string[ridx].isalpha())):\r\n",
        "        ridx += 1\r\n",
        "      phones += phones_for_word_fb(string[lidx:ridx].lower())\r\n",
        "      lidx = ridx\r\n",
        "    else:\r\n",
        "      while ((ridx < len(string)) and (not string[ridx].isalpha())):\r\n",
        "        ridx += 1\r\n",
        "      doublestop = False\r\n",
        "      for c in doublestops:\r\n",
        "        if c in string[lidx:ridx]:\r\n",
        "          doublestop = True\r\n",
        "      if doublestop:\r\n",
        "        phones += ['STOP0','STOP0']\r\n",
        "      elif '--' in string[lidx:ridx]:\r\n",
        "        phones += ['STOP0','STOP0']\r\n",
        "      elif '- ' in string[lidx:ridx]:\r\n",
        "        phones += ['STOP0']\r\n",
        "      else:\r\n",
        "        singlestop = False\r\n",
        "        for c in singlestops:\r\n",
        "          if c in string[lidx:ridx]:\r\n",
        "            singlestop = True\r\n",
        "        if singlestop:\r\n",
        "          phones += ['STOP0']\r\n",
        "      lidx = ridx\r\n",
        "\r\n",
        "  return phones\r\n",
        "\r\n",
        "class Syllable:\r\n",
        "  # initialization takes a list of phones\r\n",
        "  # assuming exactly one vowel/stop in them.\r\n",
        "  #\r\n",
        "  # vowel - vowel phone (w/o stress indicator) or STOP\r\n",
        "  # stress - 0 for STOP, 1 for unstressed, 2 2ndary stress, 3 primary stress\r\n",
        "  # (note this is different from the arpabet numbers)\r\n",
        "  # cfeat - Counter containing a count of the consonant features\r\n",
        "  # vfeat - Counter containing a count of the vowel features\r\n",
        "  def __init__(self, phoneslist):\r\n",
        "    phones = \" \".join(phoneslist)\r\n",
        "    for v in vowels:\r\n",
        "      loc = phones.find(v)\r\n",
        "      if (loc != -1):\r\n",
        "        self.vowel = v\r\n",
        "        if (v == 'STOP'):\r\n",
        "          self.stress = 0\r\n",
        "        elif (phones[loc + 2] == '0'):\r\n",
        "          self.stress = 1\r\n",
        "        elif (phones[loc + 2] == '1'):\r\n",
        "          self.stress = 3\r\n",
        "        elif (phones[loc + 2] == '2'):\r\n",
        "          self.stress = 2\r\n",
        "      \r\n",
        "      self.cfeat = Counter()\r\n",
        "      self.vfeat = Counter()\r\n",
        "      for p in phoneslist:\r\n",
        "        if isVowel(p):\r\n",
        "          for feature in pfm[p[0:-1]]:\r\n",
        "            self.vfeat[feature] += 1\r\n",
        "        else:\r\n",
        "          for feature in pfm[p]:\r\n",
        "            self.cfeat[feature] += 1\r\n",
        "                \r\n",
        "def distance(syl1 : Syllable, syl2 : Syllable):\r\n",
        "  \"\"\"A distance metric between two Syllable objects.\r\n",
        "  Adjusted by the constant weights in the first cell,\r\n",
        "  applied to Manhattan distance on features.\r\n",
        "  (STOP is close to every other vowel in features,\r\n",
        "  though not in stress)\r\n",
        "  \"\"\"\r\n",
        "  cdist = 0\r\n",
        "  vdist = 0\r\n",
        "  \r\n",
        "  sdist = abs(syl1.stress - syl2.stress) * kDistanceWeightStress\r\n",
        "\r\n",
        "  cdiff = difference(syl1.cfeat,syl2.cfeat)\r\n",
        "  for f in cdiff:\r\n",
        "    cdist += abs(cdiff[f]) * kDistanceWeightConsonants\r\n",
        "  \r\n",
        "  if (syl1.vowel != 'STOP' and syl2.vowel != 'STOP'):\r\n",
        "    vdiff = difference(syl1.vfeat,syl2.vfeat)\r\n",
        "    for f in vdiff:\r\n",
        "      vdist += abs(vdiff[f]) * kDistanceWeightVowels\r\n",
        "\r\n",
        "  return sdist + vdist + cdist\r\n",
        "\r\n",
        "def difference(ctr1 : Counter, ctr2 : Counter):\r\n",
        "  \"\"\"A new counter that's the difference between two Counters.\r\n",
        "  (Counter.subtract mutates the Counter, which isn't what we want.)\r\n",
        "  \"\"\"\r\n",
        "  diff = Counter(ctr1)\r\n",
        "  for c in ctr2:\r\n",
        "    diff[c] -= ctr2[c]\r\n",
        "  \r\n",
        "  return diff\r\n",
        "\r\n",
        "def isVowel(phone):\r\n",
        "  return phone[0:-1] in vowels\r\n",
        "  \r\n",
        "def syllabifier(phoneslist):\r\n",
        "  \"\"\"Turns a list of phones into a list of Syllable objects.\"\"\"\r\n",
        "\r\n",
        "  i = j = nextSylStart = 0\r\n",
        "  syllableList = []\r\n",
        "\r\n",
        "  while i < len(phoneslist):\r\n",
        "    thisSyllablePhones = []\r\n",
        "    j = i\r\n",
        "    needVowel = True\r\n",
        "    \r\n",
        "    while j < len(phoneslist) and (needVowel or not isVowel(phoneslist[j])):\r\n",
        "      if isVowel(phoneslist[j]):\r\n",
        "        needVowel = False\r\n",
        "        nextSylStart = j + 1\r\n",
        "      thisSyllablePhones.append(phoneslist[j])\r\n",
        "      \r\n",
        "      j = j + 1\r\n",
        "    \r\n",
        "    # only add a syllable if we picked up a vowel\r\n",
        "    if not needVowel:\r\n",
        "      syllableList.append(Syllable(thisSyllablePhones))\r\n",
        "      i = nextSylStart\r\n",
        "    else:\r\n",
        "      i = j\r\n",
        "\r\n",
        "  return syllableList\r\n",
        "\r\n",
        "def canonFit(list1, list2, offset):\r\n",
        "  \"\"\"Given two syllable lists and a canon offset,\r\n",
        "  returns the total syllable distance. Lower is rhymier.\r\n",
        "  list2 starts offset syllables later.\"\"\"\r\n",
        "\r\n",
        "  i = totalDist = 0\r\n",
        "  while (i + offset < len(list1) and i < len(list2)):\r\n",
        "    totalDist += distance(list2[i], list1[i + offset])\r\n",
        "    i = i + 1\r\n",
        "  \r\n",
        "  return totalDist"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcjQ0BKKELvx"
      },
      "source": [
        "def generateCanon(alts = 100, tokensPerIncrement = 5, length = 100,\r\n",
        "                  prompt = \"If only I could be a little more\",\r\n",
        "                  temperature = 1.2, top_p = 0.9, offset = 10,\r\n",
        "                  startingTokens=10):\r\n",
        "  \"\"\"\r\n",
        "  alts - number of samples of text to generate to test for rhymes\r\n",
        "  tokensPerIncrement - size of each incremental sample\r\n",
        "  length - total tokens (including the prompt)\r\n",
        "  prompt - start of canon\r\n",
        "  temperature, top_p - passed along to GPT-2\r\n",
        "  offset - how many syllables the 2nd part of the canon is delayed\r\n",
        "  startingTokens - tokens for first generation. Should be more tokens than the\r\n",
        "    prompt (tricky, because it's not clear how many tokens the prompt will contain)\r\n",
        "  \"\"\"\r\n",
        "  print(prompt)\r\n",
        "  canonSoFar = prompt\r\n",
        "  seed = 0\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "  for i in range(startingTokens, length, tokensPerIncrement):\r\n",
        "    canonSoFarSyllables = syllabifier(arpabetPlusFromText(canonSoFar))  \r\n",
        "    bestTrial = canonSoFar\r\n",
        "    bestDist = float(\"inf\")\r\n",
        "\r\n",
        "    for j in range(alts):\r\n",
        "      seed += 1\r\n",
        "      random.seed(seed)\r\n",
        "      trial = ai.generate_one(\r\n",
        "              prompt=canonSoFar,\r\n",
        "              max_length=i,\r\n",
        "              temperature=temperature,\r\n",
        "              top_p=top_p)\r\n",
        "      trialDiff = trial[len(canonSoFar):]\r\n",
        "      trialSyllables = canonSoFarSyllables + syllabifier(arpabetPlusFromText(trialDiff))\r\n",
        "      if len(trialSyllables) > len(canonSoFarSyllables): # only test generations with real new text\r\n",
        "        trialFit = canonFit(trialSyllables, canonSoFarSyllables, offset)\r\n",
        "        if trialFit < bestDist:\r\n",
        "          bestDist = trialFit\r\n",
        "          bestTrial = trial\r\n",
        "    \r\n",
        "    canonSoFar = bestTrial\r\n",
        "    print(canonSoFar)\r\n",
        "\r\n",
        "  print()\r\n",
        "  print(\"FINAL CANON:\")\r\n",
        "  print(canonSoFar)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMJq4r23Iolk",
        "outputId": "ab2abdc9-773b-40a8-f15c-8f547f4530ac"
      },
      "source": [
        "generateCanon(alts = 50, tokensPerIncrement=5, length=200, prompt=\"If only I could be\", offset = 3, temperature = 1, top_p = 0.9)\r\n"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If only I could be\n",
            "If only I could be out there more.\n",
            "\n",
            "If only I could be out there more.\n",
            "[10P] and\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-l\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\"\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-l\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-l\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-l\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-l\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "\n",
            "\n",
            "FINAL CANON:\n",
            "If only I could be out there more.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "Every part of the family keeps a performance of \"Do the Rumsos the Rumsos\" before the performance, and the choreography is perfect for the occasion.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "[10P] and [Fez-lawn] are dancing so beautifully it almost makes me want to scream every time I pass them.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WH8dvGm2miz"
      },
      "source": [
        "\r\n",
        "\r\n",
        "```\r\n",
        "If  only I  could be in that  boat.       That boat.\r\n",
        "            If    only  I     could be in that boat.\r\n",
        "\r\n",
        "I    don't know why.       Cousinwog, cousin of  Brassy and\r\n",
        "That boat.         I don't know why.  Cousinwog,     cousin \r\n",
        "\r\n",
        "Red from    Cousinwog  and   Mighty from   Cousinwog  \r\n",
        "of  Brassy     and Red from  Cousinwog    and Mighty from\r\n",
        "\r\n",
        "City  and  Plateaus  aren't  together        anymore.   They're\r\n",
        "Cousinwog  City      and     Plateaus aren't together anymore. \r\n",
        "\r\n",
        "having a breakout and Plateaus says \"What's going    on    here?\"\r\n",
        "      They're having   a breakout    and    Plateaus says \"What's\r\n",
        "\r\n",
        "going on here?\"\r\n",
        "```\r\n",
        "\r\n",
        "(offset of 4, temperature .7)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw7ljx8z7Gid"
      },
      "source": [
        "\r\n",
        "\r\n",
        "```\r\n",
        "If only I  could be my good   editor     in one piece \r\n",
        "        If only     I  could  be my good editor\r\n",
        "\r\n",
        "-- which, at least,   it   was, when  absolutely forced and wri-\r\n",
        "editor   --  which at least,    it   was, when absolutely\r\n",
        "\r\n",
        "ting   ridiculously    long chunks of crap chunks.\r\n",
        "forced and writing ridiculously       long chunks of crap\r\n",
        "\r\n",
        "Without the   ethics.          \"It sucks.\"    Sometimes,\r\n",
        "chunks.       Without  the  ethics.       \"It sucks.\"\r\n",
        "\r\n",
        "sometimes, it's just \"it's difficult       to tell a\r\n",
        "Sometimes, sometimes,      it's just \"it's difficult\r\n",
        "\r\n",
        "story\"   as art,   or an illusion.    There's another,     ever\r\n",
        "to tell  a  story\" as art, or an illusion.       There's another,\r\n",
        "\r\n",
        "another trance.  Sometimes it's \"I don't  think it's\r\n",
        "   ever another  trance.        Sometimes it's  \"I\r\n",
        "\r\n",
        "important\"         as   entertainment.\r\n",
        "don't think it's   important\" as  entertainment.\r\n",
        "```\r\n",
        "(offset of 3, temperature 2.0, vowels 4, stress 3, consonants 5)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGcVE1FaA4hj"
      },
      "source": [
        "```\r\n",
        "If only I could be allowed to  be loved.     Been  avoiding\r\n",
        "          If    only  I  could be allowed to be    loved.\r\n",
        "\r\n",
        "eye  doctor since  ninety-two.\r\n",
        "Been avoiding      eye doctor  since ninety-two.\r\n",
        "```\r\n",
        "\r\n",
        "(offset of 4, temperature 2, vowels, stress, cons = 2,1,2; 3 tokens per increment)\r\n",
        "\r\n",
        "```\r\n",
        "If only I could be that good.\r\n",
        "People say it - \"It's true it isn't\" - \"It is\", \"It is true it is true\" - \"Dear @lukejchengnott, in what way?\"\r\n",
        "```\r\n",
        "\r\n",
        "(same settings, but offset of 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAhT-dl3H8oB"
      },
      "source": [
        "```\r\n",
        "If only\r\n",
        "I could be\r\n",
        "as good as\r\n",
        "this.\r\n",
        "I know I'm\r\n",
        "doing ev\r\n",
        "ery thing right.\r\n",
        "          I\r\n",
        "know I'm do\r\n",
        "ing every\r\n",
        "thing I can.\r\n",
        "          I\r\n",
        "know I'm do\r\n",
        "ing every\r\n",
        "thing I can.\r\n",
        "          I\r\n",
        "know I'm cap\r\n",
        "able.\r\n",
        "     I be\r\n",
        "lieve I am\r\n",
        "loved.\r\n",
        "I believe\r\n",
        "I am ent\r\n",
        "ertaining\r\n",
        "the impos\r\n",
        "sible.\r\n",
        "  But all\r\n",
        "of a   sud\r\n",
        "den it seems\r\n",
        "like it's a\r\n",
        "bout to col\r\n",
        "lapse on it\r\n",
        "self and I\r\n",
        "have to find\r\n",
        "a place to\r\n",
        "stand,  so\r\n",
        "I don't lis\r\n",
        "ten.\r\n",
        "Finally\r\n",
        "I find a\r\n",
        "place to sit,\r\n",
        "   thinking\r\n",
        "it's okay\r\n",
        "to be there.\r\n",
        "      There\r\n",
        "is a rea\r\n",
        "sonable\r\n",
        "place to go,\r\n",
        "    but I'm\r\n",
        "worried it\r\n",
        "will be rai\r\n",
        "ded by the\r\n",
        "big demon\r\n",
        "ic fuckups,\r\n",
        "   and killed.\r\n",
        "          I\r\n",
        "know that I\r\n",
        "am allowed\r\n",
        "to feel my\r\n",
        "anger and\r\n",
        "anxie\r\n",
        "ty under\r\n",
        "control,\r\n",
        "that this is\r\n",
        "an extreme\r\n",
        "ly danger\r\n",
        "ous place.\r\n",
        "    I sit\r\n",
        "on it,\r\n",
        "thinking it's\r\n",
        "really o\r\n",
        "kay to be\r\n",
        "there.\r\n",
        "But then I\r\n",
        "get really\r\n",
        "worried and\r\n",
        "angry   and\r\n",
        "a     pile  of\r\n",
        "Trash piles up.\r\n",
        "```\r\n",
        "\r\n",
        "(alts -> 50 from 250, 5 tokens per increment, temperature 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77lE-sKzKLGt"
      },
      "source": [
        "(stress weight 1->200, offset -> 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ohIoeqXahkw",
        "outputId": "17cf1377-cc55-410a-ed5a-6c3c15c4ca1c"
      },
      "source": [
        "kDistanceWeightVowels = 2.0\r\n",
        "kDistanceWeightStress = 10.0\r\n",
        "kDistanceWeightConsonants = 5.0\r\n",
        "\r\n",
        "s = syllabifier(arpabetPlusFromText(\"the road the road the road the road\"))\r\n",
        "canonFit(s,s,2)"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC8S25A6C-tP"
      },
      "source": [
        "todo: don't choke on accented characters."
      ]
    }
  ]
}